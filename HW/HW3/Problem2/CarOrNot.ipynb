{"cells":[{"cell_type":"markdown","metadata":{"id":"tD7CwF07Kt3k"},"source":["# NAVARCH 565 FA 24 Homework 3"]},{"cell_type":"markdown","metadata":{"id":"4npv_MTFKymD"},"source":["### File Submission Instructions\n","\n","#### Submit 3 Files:\n","- `Problem1.py`\n","- `Problem2.py`\n","- `YourNet.pth`\n","\n","Please submit the Python files (`Problem1.py`, `Problem2.py`) along with one trained network file (`YourNet.pth`) that you will generate from Problem 2 (see below). Make sure to name the checkpoint files as **`YourNet.pth`**, as the autograder will look for this specific filename.\n","\n","Enjoy learning Geometry and Basic Deep Learning!"]},{"cell_type":"markdown","metadata":{"id":"ap8zVbPZ7htj"},"source":["# Objectives\n","\n","In this assignment, we will learn to create and train a neural network for image classification. In the task of image classification, we are given an image as input and asked to classify the image within one of a set number of classes. In this case, we will train a network to classify images as one of three labels: car, person, or neither. This information can be especially useful for a self-driving car seeking to identify dynamic objects.\n","\n","Before we start, take a quick read through the PyTorch tutorial on image classification: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html. We will be referencing the tutorial throughout, and in the end of the assignment you will get a chance to improve upon the network."]},{"cell_type":"markdown","metadata":{"id":"gOn1NRJIK081"},"source":["# Setup Code\n","Before getting started we need to run some boilerplate code to set up our environment. You'll need to rerun this setup code each time you start the notebook.\n","\n","First, run this cell load the [autoreload](https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html?highlight=autoreload) extension. This allows us to edit `.py` source files, and re-import them into the notebook for a seamless editing and debugging experience."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YS2yuFYJJeP_"},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"markdown","metadata":{"id":"CU17Vv24K5cI"},"source":["### Google Colab Setup\n","\n","Next we need to run a few commands to set up our environment on Google Colab. If you are running this notebook on a local machine you can skip this section.\n","\n","Run the following cell to mount your Google Drive. If prompted \"Permit this notebook to access your Google Drive files?\", select \"Connect to Google Drive\", and sign in to your Google account (the same account you used to store this notebook)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9_wVy2eIJhTG"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"te-WJh26K862"},"source":["### Path configuration\n","Now recall the path in your Google Drive where you uploaded this notebook, fill it in below. If everything is working correctly then running the folowing cell should print the filenames from the assignment:\n","\n","```\n","['utils.py', 'Problem2.py', 'Data', 'CarOrNot.ipynb']\n","```\n","\n","If you are working on a local machine, just set `GOOGLE_DRIVE_PATH` to the path of your `Problem1` folder."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zt2IYQMFJh1f"},"outputs":[],"source":["import os\n","\n","# TODO: Fill in the Google Drive path where you uploaded the assignment\n","# Example: If you create a 2024FA folder and put all the files under A3 folder, then '2024FA/A3/Problem2'\n","GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = \"student 2/Problem2\"\n","GOOGLE_DRIVE_PATH = os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n","print(os.listdir(GOOGLE_DRIVE_PATH))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"omtqsZhJJo8n"},"outputs":[],"source":["import sys\n","sys.path.append(GOOGLE_DRIVE_PATH)\n","\n","import time, os\n","os.environ[\"TZ\"] = \"US/Eastern\"\n","time.tzset()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kAnZFt8vJuxr"},"outputs":[],"source":["# Imports\n","import numpy as np\n","import torch\n","import yaml\n","\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"DLycJLMLYE0K"},"source":["Next we will check if a GPU is available"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-C3tfiOqYEJt"},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Using device:', device)"]},{"cell_type":"markdown","metadata":{"id":"lMpAIVpSLGXw"},"source":["Once you have successfully mounted your Google Drive and located the path to this assignment, run the following cell to allow us to import from the `.py` files of this assignment. If it works correctly, it should print the message:\n","\n","```\n","Welcome to assignment 3!\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XZQwmGMxJ0jD"},"outputs":[],"source":["from utils import *\n","from Problem2 import *\n","hello()\n","\n","py_path = os.path.join(GOOGLE_DRIVE_PATH, 'Problem2.py')\n","py_edit_time = time.ctime(os.path.getmtime(py_path))\n","print('Problem2.py last edited on %s' % py_edit_time)"]},{"cell_type":"markdown","metadata":{"id":"Hd_yQryz8g25"},"source":["# Data Visualization\n","\n","First, let's take a look at some examples of images from the dataset to get a feel for the data. Navigate to the `Train` folder within the `Data` folder to take a look at some of the example images our network will be tasked with labeling. Notice that the images are all of different sizes, which can be challenging for our network."]},{"cell_type":"markdown","metadata":{"id":"YvhUGdsuLK9D"},"source":["### PyTorch Imports and Parameters\n","\n","We need some imports for PyTorch to run, which are found in the code cell below. We also need to set some hyper-parameters. Don't worry about these for now, later you will get a chance to tune them.\n","\n","\n","\n","*   `batch_size` is the number of data examples within a mini-batch.\n","*   `lr` is the learning rate of the network.\n","*   `num_epochs` is the number of epochs, or times the network will train on each individual example.\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MFUxtWlzLwU2"},"outputs":[],"source":["import torch\n","import torchvision\n","import matplotlib.pyplot as plt\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uW999iOoD3NC"},"outputs":[],"source":["batch_size = 4\n","lr = 0.0003\n","num_epochs = 10"]},{"cell_type":"markdown","metadata":{"id":"qAXADT6Y9gVp"},"source":["### Data Loader\n","Next, we will create data loaders for the training and validation set. Take a look in your Python file at the class `Cars` to how PyTorch datasets are created. Later in your final project you will need to create your own data loaders.\n","\n","Remember how the images were all of different sizes? Fortunately, PyTorch includes special data transformation functions for us to transform each image to the same size. Check out the `transform_train()` function to see how this is accomplished."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5_hdyW9VNuQV"},"outputs":[],"source":["trainset = Cars(os.path.join(GOOGLE_DRIVE_PATH, \"Data\", \"Train\"),\n","                transform=transform_train(), device=device)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n","                                          shuffle=True,\n","                                          collate_fn=trainset.collate_fn)\n","\n","valset = Cars(os.path.join(GOOGLE_DRIVE_PATH, \"Data\", \"Val\"),\n","                transform=transform_test(), device=device)\n","val_loader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n","                                          shuffle=True,\n","                                          collate_fn=valset.collate_fn)\n","\n","classes = ('None', 'Car', 'Person')"]},{"cell_type":"markdown","metadata":{"id":"bGDVfwAJ91_F"},"source":["Now that we have a data loader, we can take a look at some of the transformed images. Since the PyTorch classification tutorial is on 32x32 pixel images, we will stick with the same. Unfortunately, at that resolution it is difficult to distinguish objects in some of the images. Later, you will get a chance to modify the transformation pipeline and network to operate on your choice of image resolutions."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fMO74YC1NjPg"},"outputs":[],"source":["def imshow(img):\n","    img = img / 2 + 0.5     # unnormalize\n","    npimg = img.numpy()\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","    plt.show()\n","\n","\n","# get some random training images\n","dataiter = iter(trainloader)\n","images, labels = next(dataiter)\n","\n","# show images\n","imshow(torchvision.utils.make_grid(images))\n","# print labels\n","print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"]},{"cell_type":"markdown","metadata":{"id":"O-e5DHfA-icG"},"source":["# Hello World\n","Now is your chance to create your first network! Read through the PyTorch image classification documentation and implement the demo network in class `TutorialNet`. Note that you will need to make a modification to the network, changing the output size of the last layer to 3 in order to match the number of classes in our dataset.\n","\n","To train our network, we will use the Cross Entropy Loss (https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) and Adam optimizer (https://pytorch.org/docs/stable/generated/torch.optim.Adam.html)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"78RCzMGHOJVH"},"outputs":[],"source":["# https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n","net = TutorialNet().to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=1e-5)"]},{"cell_type":"markdown","metadata":{"id":"4XVaAgouAJln"},"source":["Now that the network is created, we can try to run it! Note that you do not need GPU for this assignment, and CPU will be sufficient.\n","\n","The training function is structured as a loop over the number of epochs. Within each epoch, the network first trains over the entire training dataset. Some important steps when training are to:\n","1.   Zero (reset) the gradient.\n","2.   Calculate predictions and a loss function from the predictions.\n","3.   Call `backward()` to calculate the gradient.\n","4.   Step the optimizer to update the network parameters.\n","\n","After the training loop, we also iterate over the validation set to understand how well the network is fitting the data. If the network is fitting the training set but not the validation set, this is known as over-fitting and indicates the network may not adapt well to new data.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GHBVwUSyOhIl"},"outputs":[],"source":["def train_net(net, trainloader, val_loader, device, num_epochs):\n","  for epoch in range(num_epochs):  # loop over the dataset multiple times\n","      # Train\n","      net.train()\n","      running_loss = 0.0\n","      num_iters = 0\n","      for i, data in enumerate(trainloader, 0):\n","          # get the inputs; data is a list of [inputs, labels]\n","          inputs, labels = data\n","          inputs = inputs.to(device)\n","          labels = labels.to(device)\n","\n","          # zero the parameter gradients\n","          optimizer.zero_grad()\n","\n","          # forward + backward + optimize\n","          outputs = net(inputs)\n","          loss = criterion(outputs, labels)\n","          loss.backward()\n","          optimizer.step()\n","\n","          running_loss += loss.item()\n","          num_iters += labels.shape[0]\n","\n","      # print statistics\n","      print(f'epochs: {epoch + 1} loss: {running_loss / num_iters:.3f}')\n","      running_loss = 0.0\n","      num_iters = 0\n","\n","      # Validate\n","      num_correct = 0\n","      num_total = 0\n","      net.eval()\n","      with torch.no_grad():\n","        for i, data in enumerate(val_loader, 0):\n","            # get the inputs; data is a list of [inputs, labels]\n","            inputs, labels = data\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            outputs = net(inputs)\n","\n","            # Check correct\n","            _, predicted = torch.max(outputs, 1)\n","            num_correct += torch.sum(predicted == labels)\n","            num_total += predicted.shape[0]\n","\n","      # print statistics\n","      print(f'epochs: {epoch + 1} Accuracy Val: {100 * num_correct / num_total:.3f}')\n","  print('Finished Training')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YvWhquSpEcnF"},"outputs":[],"source":["train_net(net, trainloader, val_loader, device, num_epochs)"]},{"cell_type":"markdown","metadata":{"id":"YJpDb_zrBTtR"},"source":["### Save Network\n","Next, we will save the network to the file `TutorialNet.pth` so it can be loaded later for evaluation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qhn6JVIzg2M4"},"outputs":[],"source":["PATH = os.path.join(GOOGLE_DRIVE_PATH, 'TutorialNet.pth')\n","torch.save(net.state_dict(), PATH)"]},{"cell_type":"markdown","metadata":{"id":"DHlqILdyBeKA"},"source":["Let's try evaluating the saved weights on some images from the validation set. Hopefully, your network predictions were similar to the ground truth. Don't worry if several predictions were wrong. Next you will get a chance to improve the training by playing with hyper-parameters, network architecture, and image resolution."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xJUzUuA7OmGN"},"outputs":[],"source":["dataiter = iter(val_loader)\n","images, labels = next(dataiter)\n","\n","# print images\n","imshow(torchvision.utils.make_grid(images))\n","print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))\n","\n","# Load state dict\n","net = TutorialNet()\n","net.load_state_dict(torch.load(PATH))\n","\n","outputs = net(images)\n","\n","_, predicted = torch.max(outputs, 1)\n","\n","print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n","                              for j in range(batch_size)))"]},{"cell_type":"markdown","metadata":{"id":"Bq4b-QZeFW-p"},"source":["# Your Turn!\n","Now that you have learned the basics, have some fun experimenting! Implement `YourNet()` with whatever layers you want. It could be a copy of the previous network, or you can make improvements. You can also try changing the hyper-parameters such as the learning rate, batch size, or number of epochs which we have copied to the cell below for your convenience. Additionally, you can change the `transform_train()` and `transform_test()` functions to have a different size or data augmentations such as `RandomHorizontalFlip()`.\n","\n","To evaluate your network, we will load the frozen weights and use your `transform_test()` function to test the classifier on a hidden test set."]},{"cell_type":"code","execution_count":27,"metadata":{"id":"THL4XG4ZCbJd","executionInfo":{"status":"ok","timestamp":1729467871405,"user_tz":240,"elapsed":165,"user":{"displayName":"Chankyo Kim","userId":"09507995828955470247"}}},"outputs":[],"source":["batch_size = 4\n","lr = 0.0003\n","num_epochs = 10"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"866_D6iQFgl2"},"outputs":[],"source":["# Recreate the data loaders in case they have changed\n","trainset = Cars(os.path.join(GOOGLE_DRIVE_PATH, \"Data\", \"Train\"),\n","                transform=transform_train(), device=device)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n","                                          shuffle=True,\n","                                          collate_fn=trainset.collate_fn)\n","\n","valset = Cars(os.path.join(GOOGLE_DRIVE_PATH, \"Data\", \"Val\"),\n","                transform=transform_test(), device=device)\n","val_loader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n","                                          shuffle=True,\n","                                          collate_fn=valset.collate_fn)\n","\n","# Load the network\n","net = YourNet().to(device)\n","\n","# Define the criterion and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=1e-5)\n","\n","# Train the network\n","train_net(net, trainloader, val_loader, device, num_epochs)\n","\n","# Save the weights\n","PATH = os.path.join(GOOGLE_DRIVE_PATH, 'YourNet.pth')\n","torch.save(net.state_dict(), PATH)"]},{"cell_type":"markdown","metadata":{"id":"zPXVxYndDD7F"},"source":["Run the following cell to visualize your saved weights"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MY_-FzXNGpIb"},"outputs":[],"source":["dataiter = iter(val_loader)\n","images, labels = next(dataiter)\n","\n","# print images\n","imshow(torchvision.utils.make_grid(images))\n","print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))\n","\n","net = YourNet()\n","net.load_state_dict(torch.load(PATH))\n","\n","outputs = net(images)\n","\n","_, predicted = torch.max(outputs, 1)\n","\n","print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n","                              for j in range(batch_size)))"]},{"cell_type":"markdown","metadata":{"id":"FH47dyhZHvTy"},"source":["# That's it!\n","When you are happy with your network's performance, submit the weights to the autograder to evaluate on the test set. We will run your network and grade the output on a hidden test set. Make sure the network is not too large, otherwise it may fail to finish running.\n","\n","This problem contains two grades:\n","*   50 points for having the correct number of classes in your network final layer\n","*   150 points from the accuracy on the test set, based on a sliding scale with partial credit.\n","\n","For submission, please submit `Problem1.py`, `Problem2.py`, and `YourNet.pth`.\n"]},{"cell_type":"code","source":[],"metadata":{"id":"mkTbbTAATRMc"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}